{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "from skimage import data, io, transform\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 14 24 36 50]\n"
     ]
    }
   ],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    \n",
    "    #Build a Graph\n",
    "    a = tf.constant([1,2,3,4,5])\n",
    "    b = tf.constant([6,7,8,9,10])\n",
    "\n",
    "    result = tf.multiply(a,b)\n",
    "\n",
    "    print(sess.run(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_directory):\n",
    "    directories = [d for d in os.listdir(data_directory) \n",
    "                   if os.path.isdir((os.path.join(data_directory,d)))] \n",
    "    \n",
    "    #print(os.listdir(data_directory))\n",
    "    labels,images = [],[]\n",
    "    \n",
    "    for d in directories:\n",
    "        label_directory = os.path.join(data_directory,d)\n",
    "        \n",
    "        file_names = [os.path.join(label_directory,f) \n",
    "                      for f in os.listdir(label_directory)\n",
    "                      if f.endswith('.ppm')]\n",
    "        \n",
    "        for f in file_names:\n",
    "            images.append(skimage.io.imread(f))\n",
    "            labels.append(int(d))\n",
    "    \n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'skimage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-472463a96315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#Training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-d1d101411415>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_directory)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'skimage' is not defined"
     ]
    }
   ],
   "source": [
    "ROOT_PATH = '/Users/ModouNiang/Desktop/Neural-Network/'\n",
    "\n",
    "#Creating Directiories containing training and testing data\n",
    "train_data_directory = os.path.join(ROOT_PATH,'Training')\n",
    "test_data_directory = os.path.join(ROOT_PATH,'Testing')\n",
    "\n",
    "#Training data\n",
    "images,labels = load_data(train_data_directory)\n",
    "\n",
    "images = np.array(images)\n",
    "#labels = np.array(labels)\n",
    "\n",
    "print(len(set(labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image Dimesions: ',images.ndim)\n",
    "print('Number of images: ',images.size)\n",
    "#print(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Label Dimensions: ',labels.ndim)\n",
    "print('Number of Labels: ',len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels,62)\n",
    "plt.title('Distribution of Traffic Sign Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing random images and displaying them within a subplot\n",
    "traffic_signs = [300,2250,3650,4000]\n",
    "\n",
    "#Creating subplots to display the random images\n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[traffic_signs[i]])\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    print('Shape: {}, Minimum: {}, Maximum: {}'.format(images[traffic_signs[i]].shape,\n",
    "                                                       images[traffic_signs[i]].min(),\n",
    "                                                       images[traffic_signs[i]].max()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Unique Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "unique_labels\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "counter = 1\n",
    "for label in unique_labels:\n",
    "    \n",
    "    image = images[labels.index(label)]\n",
    "    \n",
    "    #Define 64 subplots\n",
    "    plt.subplot(8, 8, i)\n",
    "\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.title('Label {} {}'.format(label,labels.count(label)))\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rescaling images to 28x28 images\n",
    "images28 = [transform.resize(image,(28,28)) for image in images]\n",
    "images28 = np.array(images28)\n",
    "\n",
    "#Choosing random images and displaying them within a subplot\n",
    "traffic_signs = [300,2250,3650,4000]\n",
    "\n",
    "#Creating subplots to display the random images\n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images28[traffic_signs[i]])\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    \n",
    "    print('Shape: {}, Minimum: {}, Maximum: {}'.format(images28[traffic_signs[i]].shape,\n",
    "                                                       images28[traffic_signs[i]].min(),\n",
    "                                                       images28[traffic_signs[i]].max()))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting images to grayscale\n",
    "images28 = np.array(images28)\n",
    "images28 = rgb2gray(images28)\n",
    "\n",
    "plt.imshow(images28[0])\n",
    "\n",
    "#Choosing random images and displaying them within a subplot\n",
    "traffic_signs = [300,2250,3650,4000]\n",
    "\n",
    "#Creating subplots to display the random images\n",
    "for i in range(len(traffic_signs)):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images28[traffic_signs[i]], cmap='gray')\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining placeholders for inputs and labels to be later used during the session\n",
    "x = tf.placeholder(dtype = float32, shape = [None,28,28])\n",
    "y = tf.placeholder(dtype = float32, shape = [None])\n",
    "\n",
    "#Flattening the input data\n",
    "flattened_images = tf.contrib.layers.flatten(x)\n",
    "\n",
    "#Constructing a fully connected layer that generates logits \n",
    "logits = tf.contrib.layers.fully_connected(flattened_images,62,tf.nn.relu)\n",
    "\n",
    "#Defining loss function\n",
    "loss_func = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y,\n",
    "                                                                         logits = logits))\n",
    "\n",
    "#Define optimizer\n",
    "train_op = tf.train.AdamOptimizer(learning_rate = .001).minimize(loss)\n",
    "\n",
    "#Converting logits to label indicies\n",
    "pred = tf.argmax(logits,1)\n",
    "\n",
    "#Creating an accuracy metrix\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
